<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>AI Conversation | SomeTools</title>
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta name="description" content="Watch multiple AI models converse with each other in your browser using WebLLM. Add up to 8 AIs with different personalities and models.">
  <link rel="canonical" href="https://example.com/ai/conversation">
  <link rel="stylesheet" href="/css/base.css">
  <link rel="stylesheet" href="/css/tool.css">
  <link rel="preload" href="/css/base.css" as="style">
  <link rel="icon" href="/favicon.ico" sizes="any">
  <link rel="icon" href="/assets/download-16x16.ico" sizes="16x16" type="image/x-icon">
  <link rel="icon" href="/assets/download-32x32.ico" sizes="32x32" type="image/x-icon">
  <link rel="icon" href="/assets/download-48x48.ico" sizes="48x48" type="image/x-icon">
  <link rel="icon" href="/assets/download-64x64.ico" sizes="64x64" type="image/x-icon">
  <link rel="icon" href="/assets/download-128x128.ico" sizes="128x128" type="image/x-icon">
  <link rel="icon" href="/assets/download-256x256.ico" sizes="256x256" type="image/x-icon">
  <link rel="apple-touch-icon" href="/assets/download-256x256.ico">
  <link rel="manifest" href="/manifest.webmanifest">
  <script type="module" src="/js/analytics.js"></script>
  <meta property="og:title" content="AI Conversation">
  <meta property="og:description" content="Watch multiple AI models converse with each other locally in your browser. Add up to 8 AIs with unique personalities.">
  <style>
    details.info-box summary {
      list-style: none;
    }
    details.info-box summary::-webkit-details-marker {
      display: none;
    }
    details.info-box summary::marker {
      display: none;
    }
    details.info-box summary:hover {
      opacity: 0.8;
    }
    .ai-message {
      margin-bottom: 1rem;
      padding: 0.75rem;
      border-radius: 6px;
      border: 1px solid var(--border);
    }
    .ai-message.ai1 {
      background: linear-gradient(135deg, var(--bg-elev) 0%, rgba(59, 130, 246, 0.1) 100%);
      border-left: 3px solid #3b82f6;
    }
    .ai-message.ai2 {
      background: linear-gradient(135deg, var(--bg-elev) 0%, rgba(16, 185, 129, 0.1) 100%);
      border-left: 3px solid #10b981;
    }
    .ai-message .speaker {
      font-weight: 600;
      margin-bottom: 0.25rem;
      font-size: 0.875rem;
    }
    .ai-message.ai1 .speaker {
      color: #3b82f6;
    }
    .ai-message.ai2 .speaker {
      color: #10b981;
    }
    .ai-message .content {
      white-space: pre-wrap;
      line-height: 1.5;
    }
    #model-selection-pane.collapsed {
      max-height: 60px;
      overflow: hidden;
    }
    #model-selection-content {
      transition: opacity 0.3s ease, max-height 0.3s ease;
      overflow: hidden;
    }
    #model-selection-pane.collapsed #model-selection-content {
      max-height: 0;
      opacity: 0;
      margin: 0;
      padding: 0;
      overflow: hidden;
    }
    #model-selection-toggle {
      cursor: pointer;
      transition: all 0.2s ease;
    }
    #model-selection-toggle:hover {
      background: var(--bg-hover);
    }
    @media (max-width: 1023px) {
      section.tool {
        grid-template-columns: 1fr !important;
      }
    }
  </style>
</head>
<body>
  <a href="#main" class="skip-link">Skip to main content</a>
  <header>
    <a href="/">
      <h1>SomeTools</h1>
    </a>
    <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
      <span id="theme-icon">üåô</span>
    </button>
  </header>

  <nav aria-label="Breadcrumb">
    <a href="/">Home</a>
    <a href="/ai/conversation">AI Conversation</a>
  </nav>

  <main id="main">
    <h1>AI Conversation</h1>
    <p>Watch multiple AI models have a conversation with each other, running entirely in your browser using WebLLM. Set a topic to start the conversation, add as many AIs as you want (up to 8), configure their personalities, and observe the exchange.</p>

    <details class="info-box" style="padding: 1rem; background: var(--bg-elev); border: 1px solid var(--border); border-radius: 6px; margin-bottom: 1.5rem;">
      <summary style="cursor: pointer; font-weight: 600; list-style: none; user-select: none;">
        <span style="display: inline-flex; align-items: center; gap: 0.5rem;">
          <span>‚ö†Ô∏è WebLLM Requirements</span>
          <span style="font-size: 0.875rem; color: var(--muted); font-weight: normal;">(click to expand)</span>
        </span>
      </summary>
      <div style="margin-top: 1rem;">
        <p><strong>WebLLM requires WebGPU support in your browser.</strong></p>
        <ul style="margin: 0.5rem 0; padding-left: 1.5rem;">
          <li><strong>WebGPU Support:</strong> Required for model execution. Check support at <a href="https://webgpureport.org/" target="_blank" rel="noreferrer">webgpureport.org</a></li>
          <li><strong>Browser Requirements:</strong> Chrome 113+, Edge 113+, or Safari 18+ (with WebGPU enabled)</li>
          <li><strong>Models:</strong> Large files that are downloaded once and cached in your browser's IndexedDB</li>
          <li><strong>Performance:</strong> Running multiple models simultaneously requires significant GPU memory. Smaller models are recommended.</li>
          <li>You can use the same model for multiple AIs or choose different models for each.</li>
        </ul>
      </div>
    </details>

    <section class="tool" style="position: relative; display: flex; flex-direction: column; gap: 1.5rem;">
      <div class="pane" id="model-selection-pane" style="position: relative;">
        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.5rem;">
          <label style="margin: 0;">AI Configuration</label>
          <button id="model-selection-toggle" class="secondary" style="font-size: 1.2rem; padding: 0.3rem 0.6rem; min-width: 32px;">‚àí</button>
        </div>
        <div id="model-selection-content">
          <div id="ai-configurations-container">
            <!-- AI configurations will be dynamically generated here -->
          </div>

          <div class="actions" style="margin-top: 1rem; margin-bottom: 1rem; flex-wrap: wrap; gap: 0.5rem;">
            <button id="add-ai-btn" class="secondary">+ Add Another AI</button>
            <button id="download-models-btn" class="primary">Download & Cache Models</button>
            <button id="check-models-btn">Check Models Status</button>
          </div>

          <div id="models-status" style="margin-top: 0.5rem; padding: 0.5rem; background: var(--bg-elev); border-radius: 4px; font-size: 0.875rem; color: var(--muted); white-space: pre-wrap; min-height: 3rem;"></div>
        </div>
      </div>

      <div class="pane" style="display: flex; flex-direction: column;">
        <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 1rem; margin-bottom: 1rem;">
          <div>
            <label for="temperature-input">Temperature</label>
              <input type="number" id="temperature-input" min="0" max="2" step="0.1" value="0.7" style="width: 100%;">
              <small style="color: var(--muted);">Creativity level (0.0-2.0)</small>
            </div>
            <div>
              <label for="max-tokens-input">Max Tokens</label>
              <input type="number" id="max-tokens-input" min="50" max="2048" step="50" value="256" style="width: 100%;">
              <small style="color: var(--muted);">Response length</small>
            </div>
            <div>
              <label for="max-turns-input">Max Turns</label>
              <input type="number" id="max-turns-input" min="1" max="50" step="1" value="10" style="width: 100%;">
              <small style="color: var(--muted);">Conversation length</small>
            </div>
          </div>

        <label for="conversation-topic">Conversation Topic</label>
        <textarea id="conversation-topic" rows="2" placeholder="Enter a topic or question to start the conversation... (e.g., 'Discuss the future of artificial intelligence')" style="margin-bottom: 1rem; resize: vertical;"></textarea>
        
        <div class="actions" style="margin-bottom: 1rem;">
          <button id="start-conversation-btn" class="primary">Start Conversation</button>
          <button id="pause-conversation-btn" class="secondary" disabled>Pause & Interject</button>
          <button id="stop-conversation-btn" class="secondary" disabled>Stop Conversation</button>
          <button id="clear-conversation-btn" class="secondary">Clear</button>
        </div>

        <div id="interjection-panel" style="display: none; margin-bottom: 1rem; padding: 1rem; background: var(--bg-elev); border: 2px solid var(--accent); border-radius: 6px;">
          <label for="interjection-input" style="font-weight: 600; color: var(--accent);">Your Message (Interjection)</label>
          <textarea id="interjection-input" rows="3" placeholder="Enter your message to add to the conversation..." style="margin-top: 0.5rem; margin-bottom: 0.5rem; resize: vertical;"></textarea>
          <div class="actions" style="gap: 0.5rem;">
            <button id="submit-interjection-btn" class="primary">Submit & Resume</button>
            <button id="cancel-interjection-btn" class="secondary">Cancel & Resume</button>
          </div>
          <small style="color: var(--muted); display: block; margin-top: 0.5rem;">
            üí° Your message will be added to the conversation, and the next AI will respond to it.
          </small>
        </div>

        <label for="conversation-log">Conversation</label>
        <div id="conversation-log" style="height: 600px; max-height: 600px; border: 1px solid var(--border); border-radius: 6px; background: var(--bg-elev); padding: 0.75rem; overflow-y: auto; font-size: 0.9rem;">
          <p class="text-sm text-muted">Configure your AIs, enter a conversation topic, then click "Start Conversation" to watch them discuss the topic.</p>
        </div>
      </div>
    </section>

    <section class="faq" aria-labelledby="faq-h">
      <h2 id="faq-h">FAQ</h2>
      <details>
        <summary>How does this work?</summary>
        <p>This tool loads AI models in your browser and has them converse with each other. You can add 2-8 AIs with different personalities. Each AI takes turns responding based on the full conversation history. All processing happens locally in your browser using WebLLM.</p>
      </details>
      <details>
        <summary>Can I use the same model for multiple AIs?</summary>
        <p>Yes! You can use the same model for multiple AIs. The tool will load the model once and reuse it for all AIs using that model. This is more memory-efficient than loading different models for each AI.</p>
      </details>
      <details>
        <summary>Why does it take so long to start?</summary>
        <p>If the models aren't already cached, they need to be downloaded first. Smaller models (~300MB-1GB) download quickly, while larger models can take several minutes. Once cached, they load much faster.</p>
      </details>
      <details>
        <summary>What are good settings for a conversation?</summary>
        <p>Start with 2-3 smaller models like Qwen2.5 0.5B or Llama 3.2 1B. Set temperature to 0.7-0.9 for more varied responses. Keep max tokens around 256 for faster responses. Start with 5-10 turns to see how the conversation flows. Use system instructions to give each AI a distinct personality or role for more interesting exchanges.</p>
      </details>
      <details>
        <summary>How do I add more AIs?</summary>
        <p>Click the "+ Add Another AI" button to add up to 8 AIs total. Each AI gets its own color-coded card where you can select a model and define its personality. Remove AIs with the "√ó Remove" button on their card (you need at least 1 AI).</p>
      </details>
      <details>
        <summary>How do I use system instructions?</summary>
        <p>System instructions define each AI's personality, role, or expertise. For example, you could set AI 1 as "You are a skeptical scientist who questions claims" and AI 2 as "You are an optimistic entrepreneur who sees opportunities." This creates more dynamic and interesting conversations as each AI maintains its unique perspective.</p>
      </details>
      <details>
        <summary>Is my data sent to a server?</summary>
        <p>No. All models run entirely in your browser. No prompts or responses are sent to any server.</p>
      </details>
    </section>
  </main>

  <script type="module" src="/js/header.js"></script>
  <!-- Load bundled WebLLM -->
  <script type="module">
    try {
      await import('/js/tools/bundled/webllm-bundle.js');
    } catch (e) {
      console.log('Bundled WebLLM not found. Run "npm install && npm run build" to create it.');
    }
  </script>
  <script type="module" src="/js/tools/webllm-ai-conversation.js"></script>
  <script type="module">
    import { initNotesWidget } from '/js/utils/notes-widget.js';
    initNotesWidget();
  </script>
</body>
</html>

